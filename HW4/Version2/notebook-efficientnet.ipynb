{"metadata":{"colab":{"provenance":[{"file_id":"17mW29TBZmW6jCh20ErgdmB2Jo085N_Mr","timestamp":1718009107334},{"file_id":"1K3GQyIXQdC8LNIm8ORPb7CznMKlHZof_","timestamp":1717945305733}],"collapsed_sections":["e8aa6af9"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2338260,"sourceType":"datasetVersion","datasetId":1411651}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### PyTorch官方參考範例\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html","metadata":{"id":"0d2a91ba"}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport time\nfrom PIL import Image\n\ndef CCSN_images(dataset_dir):\n    classfolder = glob.glob(os.path.join(dataset_dir,\"*\"),recursive=True)\n    class_name  = [f.split(os.path.sep)[-1] for f in classfolder]\n    img_labels  = []\n    img_list    = []\n\n    for class_id, f in enumerate(classfolder):\n        files = glob.glob(os.path.join(f,\"*.jpg\"),recursive=True)\n        img_labels.extend([class_id]*len(files))\n        img_list.extend(files)\n\n    img_labels = np.array(img_labels)\n    img_list   = np.array(img_list,dtype=object)\n\n    return img_list.reshape((-1,1)), img_labels, class_name","metadata":{"executionInfo":{"elapsed":6857,"status":"ok","timestamp":1717946334258,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"23a613fd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 定義Dataset","metadata":{"id":"d0a2769e"}},{"cell_type":"code","source":"class CCSNImageDataset(torch.utils.data.Dataset):\n    def __init__(self, img_list, img_labels, transform=None, target_transform=None):\n        self.transform        = transform\n        self.target_transform = target_transform\n        self.img_list         = img_list\n        self.img_labels       = img_labels\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = self.img_list[idx,0]\n        image    = Image.open(img_path)\n        label    = self.img_labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label\n","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717946334258,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"bcb116d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 設定CCSN資料集路徑","metadata":{"id":"071c8c97"}},{"cell_type":"code","source":"CCSNDataset_Path = \"/kaggle/input/cirrus-cumulus-stratus-nimbus-ccsn-database/CCSN_v2\"\nimg_list, img_labels, label_names = CCSN_images(CCSNDataset_Path)\n\nCCSNDataset = CCSNImageDataset(img_list,img_labels)","metadata":{"executionInfo":{"elapsed":2252,"status":"ok","timestamp":1717946336505,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"e45626c2","outputId":"0bbaef78-8337-44c8-b6d9-3c727eee56c4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 範例:透過Dataset載入並顯示部分資料集","metadata":{"id":"2f42066d"}},{"cell_type":"code","source":"N = len(CCSNDataset)\n\nplt.figure(figsize=(16,8))\n\nfor i in range(16):\n    plt.subplot(4,8,i+1)\n    image, label = CCSNDataset[np.random.randint(0,N)]\n    plt.imshow(image)\n    plt.title(label_names[label])\n    plt.axis(False)\nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":10357,"status":"ok","timestamp":1717946346858,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"e8c068b4","outputId":"32845ead-f00c-429c-9a24-c49dcda40487","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 使用預訓練模型\n列出torchvision.models裡內建預訓練模型。","metadata":{"id":"e8aa6af9"}},{"cell_type":"code","source":"import torchvision\ndir(torchvision.models)","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1717946346858,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"fabde517","outputId":"ba416529-e8a0-4f1f-a56c-f625c484c9c1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tempfile import TemporaryDirectory\n\ndef train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=25, patience = 0,scheduler = None):\n\n    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    model = model.to(device)\n\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_loss = None\n        best_acc  = 0\n        history = {'loss':[],'accuracy':[],'val_loss':[],'val_accuracy':[]}\n        patience_c = 0\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch:3d}/{num_epochs - 1}',end=' ')\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n\n                if phase == 'train' and scheduler:\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}',end=' ' if phase=='train' else '\\n')\n                if phase == 'train':\n                    history['loss'].append(epoch_loss)\n                    history['accuracy'].append(epoch_acc.cpu().numpy())\n\n                # deep copy the model\n                if phase == 'val':\n                    history['val_loss'].append(epoch_loss)\n                    history['val_accuracy'].append(epoch_acc.cpu().numpy())\n                    if best_acc < epoch_acc.cpu().numpy():\n                        best_acc = epoch_acc.cpu().numpy()\n                    if epoch == 0 or epoch_loss < best_loss:\n                        best_loss = epoch_loss\n                        patience_c= 0\n                        torch.save(model.state_dict(), best_model_params_path)\n                    else:\n                        patience_c += 1\n\n            if patience_c > patience:\n                break\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model, history\n\ndef evaluate(model, dataloader):\n\n    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    model.eval()   # Set model to evaluate mode\n\n    running_loss = 0.0\n    running_corrects = 0\n    dataset_size     = 0\n        # Iterate over data.\n    for inputs, labels in dataloader:\n\n        dataset_size += inputs.size(0)\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # forward\n        # track history if only in train\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n\n        # statistics\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / dataset_size\n    epoch_acc = running_corrects.double() / dataset_size\n\n    print(f'test Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n    return epoch_loss, epoch_acc.cpu().numpy()","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717946346858,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"e1be302b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n  import efficientnet_pytorch\nexcept:\n  !pip install efficientnet_pytorch\n  import efficientnet_pytorch\nmodel = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\nprint(model)\ndef build_efficientnet(class_number, trainable=True):\n    efficientnet = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\n\n    for param in efficientnet.parameters():\n        param.requires_grad = trainable\n\n    num_ftrs = efficientnet._fc.in_features\n    efficientnet._fc = nn.Linear(num_ftrs, class_number)\n\n    return efficientnet","metadata":{"executionInfo":{"elapsed":514,"status":"ok","timestamp":1717946347361,"user":{"displayName":"Hugo Dai","userId":"07873503290726410119"},"user_tz":-480},"id":"fe4163a2","outputId":"3cc47396-d583-4fff-9eb8-1b131d933b9c","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ndevice= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.is_available():\n    print('gpu is available')\nelse:\n    print('cpu only')\n\ndata_transforms = {\n    'train': torchvision.transforms.Compose([\n        torchvision.transforms.RandomResizedCrop(224),\n        torchvision.transforms.RandomHorizontalFlip(),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': torchvision.transforms.Compose([\n        torchvision.transforms.Resize(256),\n        torchvision.transforms.CenterCrop(224),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nskf        = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) # 80 % for training and validation sets, 20 % for the test set\n\nbatch_size = 64\nepochs     = 120\npatience   = epochs//15\n\ntest_accuracy = []\ntest_loss     = []\nhistories     = []\n\ncriterion = nn.CrossEntropyLoss()\n\n\nfor i, (train_idx, test_idx) in enumerate(skf.split(img_list,img_labels)):\n\n    print('-'*50)\n\n    X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(img_list[train_idx],img_labels[train_idx],test_size=0.2,random_state=i)\n\n    testloader = torch.utils.data.DataLoader(CCSNImageDataset(img_list[test_idx],img_labels[test_idx],data_transforms['train'],lambda x : torch.tensor(x,dtype=torch.long)),batch_size=1,shuffle=True)\n    trainloader= torch.utils.data.DataLoader(CCSNImageDataset(X_train,y_train,data_transforms['train'],lambda x : torch.tensor(x,dtype=torch.long)),batch_size=batch_size,shuffle=True)\n    validloader= torch.utils.data.DataLoader(CCSNImageDataset(X_valid,y_valid,data_transforms['val'],lambda x : torch.tensor(x,dtype=torch.long)),batch_size=batch_size,shuffle=True)\n\n    efficientnet = build_efficientnet(len(label_names),True)\n    efficientnet = efficientnet.to(device)\n    # Observe that all parameters are being optimized\n    optimizer_ft = optim.AdamW(efficientnet.parameters())\n\n    trained_model, history = train_model(efficientnet, criterion, optimizer_ft,\n                                         dataloaders={'train':trainloader,'val':validloader},\n                                         dataset_sizes={'train':X_train.shape[0],'val':X_valid.shape[0]},\n                                         patience=patience,\n                                         num_epochs=epochs,\n                                         scheduler = None)\n\n    histories.append(history)\n    print(f'Fold {i+1:2d}',end=' ')\n    loss, acc = evaluate(trained_model, testloader)\n\n    test_loss.append(loss)\n    test_accuracy.append(acc)","metadata":{"id":"1d58d6f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 顯示結果","metadata":{"id":"fbec7d98"}},{"cell_type":"code","source":"plt.figure(figsize=(8,3*len(histories)))\n\nmax_loss = 0\nmax_acc  = 0\nfor i,history in enumerate(histories):\n    max_loss = max(max_loss,np.max(history['loss']),np.max(history['val_loss']))\n\nmax_loss *= 1.05\nfor i,history in enumerate(histories):\n    plt.subplot(len(histories),2,i*2+1)\n    plt.title(f'fold:{i+1}')\n    plt.plot(history['loss'],label='train')\n    plt.plot(history['val_loss'],label='valid')\n    plt.xlabel('epoch')\n    step = int(np.ceil(len(history['loss'])/5))\n    plt.xticks(np.arange(0,len(history['loss']),step),[str(u+1) for u in np.arange(0,len(history['loss']),step)])\n    plt.ylabel('loss')\n    plt.ylim([0,max_loss])\n    plt.grid(True)\n    plt.legend()\n\n    plt.subplot(len(histories),2,i*2+2)\n    plt.title(f'fold:{i+1}')\n    plt.plot(history['accuracy'],label='train')\n    plt.plot(history['val_accuracy'],label='valid')\n    plt.xticks(np.arange(0,len(history['accuracy']),step),[str(u+1) for u in np.arange(0,len(history['accuracy']),step)])\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.ylim([0,1.0])\n    plt.grid(True)\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\nplt.figure()\nplt.bar(x=np.arange(len(test_accuracy)),height=np.array(test_accuracy))\nplt.xlabel('fold')\nplt.xticks(np.arange(len(test_accuracy)),[str(i+1) for i in np.arange(len(test_accuracy))])\nplt.ylabel('accuracy')\nplt.title(f'average accuracy rate:{np.mean(np.array(test_accuracy)):.3f}+/-{np.std(np.array(test_accuracy)):.3f}')\nplt.grid(True)\nplt.ylim([0,1.0])\nplt.show()\nprint(f'average accuracy rate:{np.mean(np.array(test_accuracy)):.3f}+/-{np.std(np.array(test_accuracy)):.3f}')","metadata":{"id":"65411688","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"38cc44ca"},"execution_count":null,"outputs":[]}]}